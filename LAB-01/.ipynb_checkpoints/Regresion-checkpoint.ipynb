{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu  \n",
    "Fakultet elektrotehnike i računarstva  \n",
    "  \n",
    "## Strojno učenje 2019/2020  \n",
    "http://www.fer.unizg.hr/predmet/su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "### Laboratorijska vježba 1: Regresija\n",
    "\n",
    "*Verzija: 1.2  \n",
    "Zadnji put ažurirano: 27. rujna 2019.*\n",
    "\n",
    "(c) 2015-2019 Jan Šnajder, Domagoj Alagić \n",
    "\n",
    "Objavljeno: **30. rujna 2019.**  \n",
    "Rok za predaju: **21. listopada 2019. u 07:00h**\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upute\n",
    "\n",
    "Prva laboratorijska vježba sastoji se od deset zadataka. U nastavku slijedite upute navedene u ćelijama s tekstom. Rješavanje vježbe svodi se na **dopunjavanje ove bilježnice**: umetanja ćelije ili više njih **ispod** teksta zadatka, pisanja odgovarajućeg kôda te evaluiranja ćelija. \n",
    "\n",
    "Osigurajte da u potpunosti **razumijete** kôd koji ste napisali. Kod predaje vježbe, morate biti u stanju na zahtjev asistenta (ili demonstratora) preinačiti i ponovno evaluirati Vaš kôd. Nadalje, morate razumjeti teorijske osnove onoga što radite, u okvirima onoga što smo obradili na predavanju. Ispod nekih zadataka možete naći i pitanja koja služe kao smjernice za bolje razumijevanje gradiva (**nemojte pisati** odgovore na pitanja u bilježnicu). Stoga se nemojte ograničiti samo na to da riješite zadatak, nego slobodno eksperimentirajte. To upravo i jest svrha ovih vježbi.\n",
    "\n",
    "Vježbe trebate raditi **samostalno**. Možete se konzultirati s drugima o načelnom načinu rješavanja, ali u konačnici morate sami odraditi vježbu. U protivnome vježba nema smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Učitaj osnovne biblioteke...\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Jednostavna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadan je skup primjera $\\mathcal{D}=\\{(x^{(i)},y^{(i)})\\}_{i=1}^4 = \\{(0,4),(1,1),(2,2),(4,5)\\}$. Primjere predstavite matrixom $\\mathbf{X}$ dimenzija $N\\times n$ (u ovom slučaju $4\\times 1$) i vektorom oznaka $\\textbf{y}$, dimenzija $N\\times 1$ (u ovom slučaju $4\\times 1$), na sljedeći način:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [4]]\n",
      "[4 1 2 5]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0],[1],[2],[4]])\n",
    "y = np.array([4,1,2,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Proučite funkciju [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) iz biblioteke `sklearn` i upotrijebite je za generiranje matrice dizajna $\\mathbf{\\Phi}$ koja ne koristi preslikavanje u prostor više dimenzije (samo će svakom primjeru biti dodane *dummy* jedinice; $m=n+1$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 2.],\n",
       "       [1., 4.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(1)\n",
    "o = poly.fit_transform(X)\n",
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upoznajte se s modulom [`linalg`](http://docs.scipy.org/doc/numpy/reference/routines.linalg.html). Izračunajte težine $\\mathbf{w}$ modela linearne regresije kao $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Zatim se uvjerite da isti rezultat možete dobiti izračunom pseudoinverza $\\mathbf{\\Phi}^+$ matrice dizajna, tj. $\\mathbf{w}=\\mathbf{\\Phi}^+\\mathbf{y}$, korištenjem funkcije [`pinv`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2        0.45714286]\n",
      "[2.2        0.45714286]\n"
     ]
    }
   ],
   "source": [
    "oT = o.transpose()\n",
    "w1 = linalg.inv(oT.dot(o)).dot(oT).dot(y)\n",
    "print(w1)\n",
    "w2 = linalg.pinv(o).dot(y)\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radi jasnoće, u nastavku je vektor $\\mathbf{x}$ s dodanom *dummy* jedinicom $x_0=1$ označen kao $\\tilde{\\mathbf{x}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite primjere iz $\\mathcal{D}$ i funkciju $h(\\tilde{\\mathbf{x}})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$. Izračunajte pogrešku učenja prema izrazu $E(h|\\mathcal{D})=\\frac{1}{2}\\sum_{i=1}^N(\\tilde{\\mathbf{y}}^{(i)} - h(\\tilde{\\mathbf{x}}))^2$. Možete koristiti funkciju srednje kvadratne pogreške [`mean_squared_error`]( http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) iz modula [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "**Q:** Gore definirana funkcija pogreške $E(h|\\mathcal{D})$ i funkcija srednje kvadratne pogreške nisu posve identične. U čemu je razlika? Koja je \"realnija\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2        2.65714286 3.11428571 4.02857143]\n",
      "[4 1 2 5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def h(x):\n",
    "    o = poly.fit_transform(x)\n",
    "    return o.dot(w1)\n",
    "\n",
    "print(h(X))\n",
    "print(y)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "xs = linspace(0,4).reshape(-1, 1);\n",
    "plt.plot(xs, h(xs))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uvjerite se da za primjere iz $\\mathcal{D}$ težine $\\mathbf{w}$ ne možemo naći rješavanjem sustava $\\mathbf{w}=\\mathbf{\\Phi}^{-1}\\mathbf{y}$, već da nam doista treba pseudoinverz.\n",
    "\n",
    "**Q:** Zašto je to slučaj? Bi li se problem mogao riješiti preslikavanjem primjera u višu dimenziju? Ako da, bi li to uvijek funkcioniralo, neovisno o skupu primjera $\\mathcal{D}$? Pokažite na primjeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). Uvjerite se da su težine koje izračunava ta funkcija (dostupne pomoću atributa `coef_` i `intercept_`) jednake onima koje ste izračunali gore. Izračunajte predikcije modela (metoda `predict`) i uvjerite se da je pogreška učenja identična onoj koju ste ranije izračunali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Polinomijalna regresija i utjecaj šuma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Razmotrimo sada regresiju na većem broju primjera. Definirajte funkciju `make_labels(X, f, noise=0)` koja uzima matricu neoznačenih primjera $\\mathbf{X}_{N\\times n}$ te generira vektor njihovih oznaka $\\mathbf{y}_{N\\times 1}$. Oznake se generiraju kao $y^{(i)} = f(x^{(i)})+\\mathcal{N}(0,\\sigma^2)$, gdje je $f:\\mathbb{R}^n\\to\\mathbb{R}$ stvarna funkcija koja je generirala podatke (koja nam je u stvarnosti nepoznata), a $\\sigma$ je standardna devijacija Gaussovog šuma, definirana parametrom `noise`. Za generiranje šuma možete koristiti funkciju [`numpy.random.normal`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.normal.html). \n",
    "\n",
    "Generirajte skup za učenje od $N=50$ primjera uniformno distribuiranih u intervalu $[-5,5]$ pomoću funkcije $f(x) = 5 + x -2 x^2 -5 x^3$ uz šum  $\\sigma=200$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import normal\n",
    "\n",
    "def make_labels(X, f, noise=0) :\n",
    "    # Vaš kôd ovdje\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_instances(x1, x2, N) :\n",
    "    return np.array([np.array([x]) for x in np.linspace(x1,x2,N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite taj skup funkcijom [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajte model polinomijalne regresije stupnja $d=3$. Na istom grafikonu prikažite naučeni model $h(\\mathbf{x})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$ i primjere za učenje. Izračunajte pogrešku učenja modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Odabir modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Na skupu podataka iz zadatka 2 trenirajte pet modela linearne regresije $\\mathcal{H}_d$ različite složenosti, gdje je $d$ stupanj polinoma, $d\\in\\{1,3,5,10,20\\}$. Prikažite na istome grafikonu skup za učenje i funkcije $h_d(\\mathbf{x})$ za svih pet modela (preporučujemo koristiti `plot` unutar `for` petlje). Izračunajte pogrešku učenja svakog od modela.\n",
    "\n",
    "**Q:** Koji model ima najmanju pogrešku učenja i zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razdvojite skup primjera iz zadatka 2 pomoću funkcije [`model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) na skup za učenja i skup za ispitivanje u omjeru 1:1. Prikažite na jednom grafikonu pogrešku učenja i ispitnu pogrešku za modele polinomijalne regresije $\\mathcal{H}_d$, sa stupnjem polinoma $d$ u rasponu $d\\in [1,2,\\ldots,20]$. Budući da kvadratna pogreška brzo raste za veće stupnjeve polinoma, umjesto da iscrtate izravno iznose pogrešaka, iscrtajte njihove logaritme.\n",
    "\n",
    "**NB:** Podjela na skupa za učenje i skup za ispitivanje mora za svih pet modela biti identična.\n",
    "\n",
    "**Q:** Je li rezultat u skladu s očekivanjima? Koji biste model odabrali i zašto?\n",
    "\n",
    "**Q:** Pokrenite iscrtavanje više puta. U čemu je problem? Bi li problem bio jednako izražen kad bismo imali više primjera? Zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Točnost modela ovisi o (1) njegovoj složenosti (stupanj $d$ polinoma), (2) broju primjera $N$, i (3) količini šuma. Kako biste to analizirali, nacrtajte grafikone pogrešaka kao u 3b, ali za sve kombinacija broja primjera $N\\in\\{100,200,1000\\}$ i količine šuma $\\sigma\\in\\{100,200,500\\}$ (ukupno 9 grafikona). Upotrijebite funkciju [`subplots`](http://matplotlib.org/examples/pylab_examples/subplots_demo.html) kako biste pregledno posložili grafikone u tablicu $3\\times 3$. Podatci se generiraju na isti način kao u zadatku 2.\n",
    "\n",
    "**NB:** Pobrinite se da svi grafikoni budu generirani nad usporedivim skupovima podataka, na sljedeći način. Generirajte najprije svih 1000 primjera, podijelite ih na skupove za učenje i skupove za ispitivanje (dva skupa od po 500 primjera). Zatim i od skupa za učenje i od skupa za ispitivanje načinite tri različite verzije, svaka s drugačijom količinom šuma (ukupno 2x3=6 verzija podataka). Kako bi simulirali veličinu skupa podataka, od tih dobivenih 6 skupova podataka uzorkujte trećinu, dvije trećine i sve podatke. Time ste dobili 18 skupova podataka -- skup za učenje i za testiranje za svaki od devet grafova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q:*** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regularizirana regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "U gornjim eksperimentima nismo koristili **regularizaciju**. Vratimo se najprije na primjer iz zadatka 1. Na primjerima iz tog zadatka izračunajte težine $\\mathbf{w}$ za polinomijalni regresijski model stupnja $d=3$ uz L2-regularizaciju (tzv. *ridge regression*), prema izrazu $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi}+\\lambda\\mathbf{I})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Napravite izračun težina za regularizacijske faktore $\\lambda=0$, $\\lambda=1$ i $\\lambda=10$ te usporedite dobivene težine.\n",
    "\n",
    "**Q:** Kojih je dimenzija matrica koju treba invertirati?\n",
    "\n",
    "**Q:** Po čemu se razlikuju dobivene težine i je li ta razlika očekivana? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model), koja implementira L2-regularizirani regresijski model. Parametar $\\alpha$ odgovara parametru $\\lambda$. Primijenite model na istim primjerima kao u prethodnom zadatku i ispišite težine $\\mathbf{w}$ (atributi `coef_` i `intercept_`).\n",
    "\n",
    "**Q:** Jesu li težine identične onima iz zadatka 4a? Ako nisu, objasnite zašto je to tako i kako biste to popravili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Regularizirana polinomijalna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Vratimo se na slučaj $N=50$ slučajno generiranih primjera iz zadatka 2. Trenirajte modele polinomijalne regresije $\\mathcal{H}_{\\lambda,d}$ za $\\lambda\\in\\{0,100\\}$ i $d\\in\\{2,10\\}$ (ukupno četiri modela). Skicirajte pripadne funkcije $h(\\mathbf{x})$ i primjere (na jednom grafikonu; preporučujemo koristiti `plot` unutar `for` petlje).\n",
    "\n",
    "**Q:** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "\n",
    "Kao u zadataku 3b, razdvojite primjere na skup za učenje i skup za ispitivanje u omjeru 1:1. Prikažite krivulje logaritama pogreške učenja i ispitne pogreške u ovisnosti za model $\\mathcal{H}_{d=10,\\lambda}$, podešavajući faktor regularizacije $\\lambda$ u rasponu $\\lambda\\in\\{0,1,\\dots,50\\}$.\n",
    "\n",
    "**Q:** Kojoj strani na grafikonu odgovara područje prenaučenosti, a kojoj podnaučenosti? Zašto?\n",
    "\n",
    "**Q:** Koju biste vrijednosti za $\\lambda$ izabrali na temelju ovih grafikona i zašto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. L1-regularizacija i L2-regularizacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svrha regularizacije jest potiskivanje težina modela $\\mathbf{w}$ prema nuli, kako bi model bio što jednostavniji. Složenost modela može se okarakterizirati normom pripadnog vektora težina $\\mathbf{w}$, i to tipično L2-normom ili L1-normom. Za jednom trenirani model možemo izračunati i broj ne-nul značajki, ili L0-normu, pomoću sljedeće funkcije koja prima vektor težina $\\mathbf{w}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonzeroes(coef, tol=1e-6): \n",
    "    return len(coef) - len(coef[np.isclose(0, coef, atol=tol)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Za ovaj zadatak upotrijebite skup za učenje i skup za testiranje iz zadatka 3b. Trenirajte modele **L2-regularizirane** polinomijalne regresije stupnja $d=10$, mijenjajući hiperparametar $\\lambda$ u rasponu $\\{1,2,\\dots,100\\}$. Za svaki od treniranih modela izračunajte L{0,1,2}-norme vektora težina $\\mathbf{w}$ te ih prikažite kao funkciju od $\\lambda$. Pripazite što točno šaljete u funkciju za izračun normi.\n",
    "\n",
    "**Q:** Objasnite oblik obiju krivulja. Hoće li krivulja za $\\|\\mathbf{w}\\|_2$ doseći nulu? Zašto? Je li to problem? Zašto?\n",
    "\n",
    "**Q:** Za $\\lambda=100$, koliki je postotak težina modela jednak nuli, odnosno koliko je model rijedak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glavna prednost L1-regularizirane regresije (ili *LASSO regression*) nad L2-regulariziranom regresijom jest u tome što L1-regularizirana regresija rezultira **rijetkim modelima** (engl. *sparse models*), odnosno modelima kod kojih su mnoge težine pritegnute na nulu. Pokažite da je to doista tako, ponovivši gornji eksperiment s **L1-regulariziranom** regresijom, implementiranom u klasi  [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) u modulu [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). Zanemarite upozorenja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Značajke različitih skala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Često se u praksi možemo susreti sa podatcima u kojima sve značajke nisu jednakih magnituda. Primjer jednog takvog skupa je regresijski skup podataka `grades` u kojem se predviđa prosjek ocjena studenta na studiju (1--5) na temelju dvije značajke: bodova na prijamnom ispitu (1--3000) i prosjeka ocjena u srednjoj školi. Prosjek ocjena na studiju izračunat je kao težinska suma ove dvije značajke uz dodani šum.\n",
    "\n",
    "Koristite sljedeći kôd kako biste generirali ovaj skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_points = 500\n",
    "np.random.seed(69)\n",
    "\n",
    "# Generiraj podatke o bodovima na prijamnom ispitu koristeći normalnu razdiobu i ograniči ih na interval [1, 3000].\n",
    "exam_score = np.random.normal(loc=1500.0, scale = 500.0, size = n_data_points) \n",
    "exam_score = np.round(exam_score)\n",
    "exam_score[exam_score > 3000] = 3000\n",
    "exam_score[exam_score < 0] = 0\n",
    "\n",
    "# Generiraj podatke o ocjenama iz srednje škole koristeći normalnu razdiobu i ograniči ih na interval [1, 5].\n",
    "grade_in_highschool = np.random.normal(loc=3, scale = 2.0, size = n_data_points)\n",
    "grade_in_highschool[grade_in_highschool > 5] = 5\n",
    "grade_in_highschool[grade_in_highschool < 1] = 1\n",
    "\n",
    "# Matrica dizajna.\n",
    "grades_X = np.array([exam_score,grade_in_highschool]).T\n",
    "\n",
    "# Završno, generiraj izlazne vrijednosti.\n",
    "rand_noise = np.random.normal(loc=0.0, scale = 0.5, size = n_data_points)\n",
    "exam_influence = 0.9\n",
    "grades_y = ((exam_score / 3000.0) * (exam_influence) + (grade_in_highschool / 5.0) \\\n",
    "            * (1.0 - exam_influence)) * 5.0 + rand_noise\n",
    "grades_y[grades_y < 1] = 1\n",
    "grades_y[grades_y > 5] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Iscrtajte ovisnost ciljne vrijednosti (y-os) o prvoj i o drugoj značajki (x-os). Iscrtajte dva odvojena grafa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Naučite model L2-regularizirane regresije ($\\lambda = 0.01$), na podacima `grades_X` i `grades_y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada ponovite gornji eksperiment, ali prvo skalirajte podatke `grades_X` i `grades_y` i spremite ih u varijable `grades_X_fixed` i `grades_y_fixed`. Za tu svrhu, koristite [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Gledajući grafikone iz podzadatka (a), koja značajka bi trebala imati veću magnitudu, odnosno važnost pri predikciji prosjeka na studiju? Odgovaraju li težine Vašoj intuiciji? Objasnite.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Multikolinearnost i kondicija matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Izradite skup podataka `grades_X_fixed_colinear` tako što ćete u skupu `grades_X_fixed` iz\n",
    "zadatka *7b* duplicirati zadnji stupac (ocjenu iz srednje škole). Time smo efektivno uveli savršenu multikolinearnost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovno, naučite na ovom skupu L2-regularizirani model regresije ($\\lambda = 0.01$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Usporedite iznose težina s onima koje ste dobili u zadatku *7b*. Što se dogodilo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Slučajno uzorkujte 50% elemenata iz skupa `grades_X_fixed_colinear` i naučite dva modela L2-regularizirane regresije, jedan s $\\lambda=0.01$ i jedan s $\\lambda=1000$). Ponovite ovaj pokus 10 puta (svaki put s drugim podskupom od 50% elemenata).  Za svaki model, ispišite dobiveni vektor težina u svih 10 ponavljanja te ispišite standardnu devijaciju vrijednosti svake od težina (ukupno šest standardnih devijacija, svaka dobivena nad 10 vrijednosti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako regularizacija utječe na stabilnost težina?  \n",
    "**Q:** Jesu li koeficijenti jednakih magnituda kao u prethodnom pokusu? Objasnite zašto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Koristeći [`numpy.linalg.cond`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.cond.html) izračunajte kondicijski broj matrice $\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi}+\\lambda\\mathbf{I}$, gdje je $\\mathbf{\\Phi}$ matrica dizajna (`grades_X_fixed_colinear`). Ponovite i za $\\lambda=0.01$ i za $\\lambda=10$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako regularizacija utječe na kondicijski broj matrice $\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi}+\\lambda\\mathbf{I}$?  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
